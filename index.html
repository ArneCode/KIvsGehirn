<!DOCTYPE html>
<html lang="de">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="stylesheet.css">
    <title>Künstliche Intelligenz Gehirn vergleich</title>
    <style>
        @import 'https://fonts.googleapis.com/css?family=Roboto:300,400,500';
        body {
            margin: 0 auto;
            max-width: 50em;
            font-family: "Roboto", "Helvetica", "Arial", sans-serif;
            line-height: 1.5;
            padding: 4em 1em;
           /* background-color: black;*/
            /*color: white;*/
            color: #444;
        }

        h2 {
            margin-top: 1em;
            padding-top: 1em;
        }

        h1,
        h2,
        strong {
            color: #222;
        }
        .link:hover{
            border: 2px solid black;
            border-radius: 5px;
        }
        /*link while the mouse is pressed on it*/
        .link:active{
            padding: 10px;
        }
        /*div to open sidebar on the left*/
        #sidebar-open {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            z-index: -1;
        }
        
    </style>
    <!--import stylesheet at sidebarjs.css-->
    <link rel="stylesheet" href="sidebarjs.css">

    <script type="text/javascript" src="generated_toc.js"></script>
</head>

<body>
   
    
    <div sidebarjs-toggle id="sidebar-open">Open/Close</div>
    <div sidebarjs>
      <nav>
        <div id="toc">
            <h3>Table of Contents</h3>
        </div>
      </nav>
    </div>
    <script src="sidebarjs.min.js"></script>
    <script>
    // Init SidebarJS
    var sidebarjs = new SidebarJS.SidebarElement();
    </script>
    <div id="contents">
    <!-- Header -->
    <h1>Künstliche Intelligenz Gehirn vergleich</h1>
    <h2>
        Aufbau eines neuronalen Netzwerkes    
    </h2>
    <p class="note">
        Hinweis: Hier wird sich auf eine Art von neuronalen Netzwerken beschränkt, anhand der sich Parallelen zum Gehirn gut erklären lassen. Das Gesagte trifft nicht auf jedes neuronale Netzwerk zu     
    </p>
    <p>
        Ein neuronales Netzwerk besteht, wie der Name erahnen lässt aus mehreren miteinander vernetzten Neuronen.     
    </p>    
    <img src="images/simple_neural_network.png" alt="Here should be an image"/>
    <p class="note">
        Hinweis: Neuronale Netzwerke bestehen in der Regel aus weitaus mehr Neuronen als hier dargestellt 
    </p>
    <p>
       Die Verbindungen zwischen den digitalen Neuronen entsprechen den biologischen Synapsen, die eigentlichen Neuronen allem anderem. Die Verbindungen besitzen einen Wert namens <em>weight</em>, der jede <a href="https://de.wikipedia.org/wiki/Reelle_Zahl">reelle Zahl</a> sein kann. Neuronen haben 2 Werte, ihre <em>activation</em>(0.0-1.0) und ihre <em>bias</em>(ebenfalls jede reelle Zahl). <em>Weight</em> und <em>bias</em> werden durch den Lernprozess verändert, die <em>activation</em> ändert sich bei jeder Anwendung der Netzwerkes.
    </p>
     <img src="images/compare_neurons.png" alt="Here should be an image"/>
    <p>
        Die Neuronen sind in mehreren Schichten bzw. Layers angeordnet. Jedes Neuron hat eine Verbindung zu jedem anderen in den Layers davor und danach. Die erste Layer nennt man <span class="orange">Input-Layer</span> und die Letzte <span class="magenta">Output-Layer</span>. Dazwischen können sich noch mehrere sogenannte <span class="cyan">hidden layers</span> befinden, ein simples Netzwerk kann aber auch ohne hidden layers funktionieren.
    </p>
     <img src="images/the_layers.png"/>
    <p>
        Durch diesen Aufbau lässt sich das Reiz-Reaktions-Schema auch gut auf das neuronale Netzwerk anwenden. Der <span class="orange">Reiz</span> sind hier die Informationen, die der <span class="orange">Input-Layer (dem Rezeptor)</span> übergeben werden, also die <em>activation</em> aller Neuronen der Layer. Dieser <span class="orange">Reiz</span> wird dann durch die <span class="cyan">hidden layers</span> weiter verarbeitet, die hier eine dem <span class="cyan">zentralen Nervensystem</span> ähnliche Rolle annehmen. Die <span class="magenta">Output-Layer</span> repräsentiert letztendlich den <span class="magenta">Effektor</span>, die <em>activations</em> ihrer Neuronen sind die Reaktion. Diese <em>activations</em> können dann in den eigentlichen Output übersetzt werden, z.B. Bild, Text oder Audio.    
    </p>
    <h2>Vom Input zum Output</h2>
    <p>
        Da der Input oft nicht ursprünglich aus Zahlen zwischen 0.0 und 1.0 besteht, wird der eigentliche Input in diese Form übersetzt. Bei einem Schwarz-Weiß-Bild kann z.B. die Helligkeit jedes Pixels als solch eine Zahl beschrieben werden. Für jeden Pixel muss es dann ein Neuron in der Input-Layer geben, das diesen Wert als <em>activation</em> zugewiesen bekommt.
    </p>
    <img src="images/translating_images.png"/>
    <p>
        Aus den <em>activations</em> der Input-Layer und den <em>weights</em> der Verbindungen werden dann die <em>activations</em> für die nächste Layer berechnet. So werden alle Layers nacheinander basierend auf der jeweils vorherigen Layer berechnet, bis man für die Output-Layer das Resultat erhält.    
    </p>
    <img src="images/layer_after_layer.png"/>
    <p>
        Wie funktioniert also diese Berechnung? Der Wert für jedes Neuron der Layer wird nacheinander aus jedem Neuron der vorherigen Layer und den <em>weights</em> der Verbindungen berechnet. Auch hier gibt es eine Ähnlichkeit zum biologischen Gehirn. Wenn an den Dendriten eines biologischen Neurons mehrere Aktionspotentiale gleichzeitig ankommen werden diese addiert (räumliche Summation). Das digitale Neuron erhält alle „Aktionspotentiale“ der vorherigen Layer zeitgleich und addiert diese.
    </p>
    <img src="images/weighted_sum_step1.png"/>
    <p>
        Allerdings werden diese Potentiale mit den <em>weights</em> der jeweiligen Verbindung multipliziert, um die <em>weighted sum</em> zu erhalten. Wenn man diese Funktion auf den biologischen Kontext überträgt, wäre es so,  als würden die einzelnen Synapsen verschieden gut leiten. Das ist im Gehirn aber nicht der Fall. Außerdem können die Werte dadurch negativ werden, was im menschlichen Gehirn nicht stattfindet.
    </p>
    <img src="images/weighted_sum_step2.png"/>
    <p>
        Weil die <em>weights</em> zum einen größer als 1 und zum anderen negativ sein können, ist es möglich, dass das Ergebnis nicht zwischen 0 und 1, dem Wertebereich eines Neurons liegt. Deshalb wird der Wert mithilfe einer sogenannten <em>activation-function</em> in diese Reichweite übersetzt. Es gibt verschiedene solcher Funktionen, aber eine für dieses Thema besonders interessante ist <a href="https://deepai.org/machine-learning-glossary-and-terms/relu">ReLU</a>. Hier besteht nämlich eine Analogie zum Alles-Oder-Nichts-Prinzip bei der Reizweiterleitung im Gehirn. Wenn die <em>weighted sum</em> negativ ist, ist die Aktivation des Neurons 0. Der Schwellenwert liegt hier also anders als in der Biologie bei 0.
    </p>
    <img src="images/ReLU.png"/>
    <p>
        Der Schwellenwert ist aber nur dann 0, wenn es keine <em>bias</em> gibt, bzw. diese nicht 0 ist. Die des Neurons wird zu der <em>weighted sum</em> addiert und verschiebt so den Schwellenwert für eine Aktivierung (eine positive Bias erleichtert die Aktivierung, eine negative erschwert sie).     
    </p>
    <img src="images/weighted_sum_step3.png"/>
    <p>
        Lernen bedeutet bei einem neuronalen Netzwerk nichts anderes als möglichst gute Werte für die einzelnen <em>weights</em> und <em>biases</em> zu finden.    
    </p>
    <h2>Lernen</h2>
    <h3>Wie das Gehirn lernt</h3>
    Wie das Gehirn lernt ist nicht genau bekannt. Wir würden hier zum Projekt der Gruppe verweisen die sich damit befasst.
    <p>Eine weit verbreitete Theorie wie Verbindungen zwischen Neuronen im Gehirn verstärkt werden ist die Hebbian Theory. 
        Sie besagt: „Neurons that Fire together wire together“. 
        Das heißt, dass wenn Neuronen in kurzer Abfolge Nacheinander feuern, sich die Verbindungen zwischen ihnen Verstärken.
        Will man etwa das Wort „Apfel“ ins englische übersetzen, so wird das beim Ersten mal etwas dauern. 
        Man stellt sich das so vor als würde zuerst das Neuron für das Konzept „Apfel“ aktiviert werden und dann über einen langen Umweg das Neuron für das Wort „Apple“. 
        Da das feuern des Apple-Neurons kurzzeitig auf das des Apfel-Neurons folgt, entsteht eine/verstärkt sich die Verbindung zwischen den beiden Neuronen. 
        Diese Theorie wird besser <a href="https://en.m.wikipedia.org/wiki/Hebbian_theory">hier auf Wikipedia erklärt</a>.
        Diese Methode auf neuronale Netze anzuwenden hat jedoch nur teilweise Erfolg, deshalb wurden für neuronale Netze andere lern-Techniken entwickelt.</p>
    <h3>Neuroevolution</h3>
    <p>Die einfachste ist Evolution, auch bekannt als Neuroevolution. 
        Bei dieser Technik werden mehrere Netze mit zufälligen Weights initialisiert. 
        Dann wird getestet wie gut diese Modelle arbeiten und ihnen wird eine gewisse Punkteanzahl zugeteilt. 
        Danach wird das beste Modell immer wieder leicht verändert kopiert um eine neue, bessere Generation zu erschaffen. 
        Diese Netze werden dann wieder getestet usw. . Ein Beispiel solchen Lernens kann man hier sehen:  <div class="link"><a href="https://arnecode.github.io/flappy-bird-ai/" target="_blank"><img src="images/flappyai.png" width="20%" alt="https://arnecode.github.io/flappy-bird-ai/"></a></div>
        Diese Art des Lernens ist zwar einfach, hört aber in komplexeren Aufgabenbereichen auf zu funktionieren. Deshalb gibt es noch eine andere Technik namens „Gradient Descent“</p>
    <h3>Gradient Descent</h3>
    <p>
        Hier wird das Modell anhand von vorher gesammelten Datenpaaren trainiert, dem Input und dem gewünschten Output. 
        Ein Beispiel wäre hier wie ein Mensch über einen längeren Zeitraum Flappy Bird spielt.
        Die volle Erklärung würde den Rahmen dieses Projektes sprengen, deshalb vereinfachen wir sie an vielen Stellen. 

        <details>
            <summary>Wie es wirklich funktioniert</summary>
            <iframe width="100%" height="800"
            src="https://www.youtube.com/embed?v=IHZwWFHWa-w&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi&index=2">
            </iframe>
        </details>
        Wir gehen zuerst einmal von einem sehr einfachem Neuronalen Netz aus. 
        Es hat einen Input und einen Output. Der Output soll immer der Input mal zwei sein.
        <img src="images/single_neuron.jpg">
        Wenn man das Netzwerk zuerst zufällig initialisiert, werden die Werte nichts mit dem gewünschten Ergebnis zu tun haben.
        Während des Lernens wird für jedes Datenpaar berechnet wie weit die Ausgabe des Neuronalen Netzes für einen gegebenen Input von dem gewünschten Output entfernt ist.
        <img src="images/single_neuron_output.jpg">
        Dann werden die Weights so angepasst, dass das Ergebnis eher den gewünschten ähnelt. </br>
        In diesem Fall ist der Output kleiner als das gewünschte Ergebnis. <br>
        &nbsp;&nbsp;&nbsp;&nbsp;<strong style="font-family: calibri;font-size: 15px;">→</strong> Die Verbindung zwischen Input und Output wird verstärkt.
    </p>
    <p>
        Bei mehreren Neuronen kann man sich das genauso vorstellen.
        
    </p>
<h4>Convolutional Neuronal Networks (CNN) - Rezeptives Feld</h4>
<p class="note">
       Hinweis: der Fokus liegt aufgrund des Vergleiches zum Auge nur auf der Bilderkennung     
    </p>
<h5>Rezeptives Feld:</h5>
<p>
    Auf der Netzhaut befinden sich deutlich mehr Rezeptoren als Nervenfasern im Sehnerv. Deshalb müssen die Informationen schon an diesem Punkt verrechnet und interpretiert werden. Es werden, bevor Signale in das Gehirn gelangen schon vereinfachte Muster wie z.B. Striche, Formen oder anderes dargestellt. (wie das genau funktioniert und was dabei herauskommt weiß man nicht, dafür ist das Gehirn zu wenig erforscht)
</p>
<h6>Convolutional Neuronal Networks:</h6>
<p>
    CNNs sind eine Form von hidden layers bestehend aus Filtern. Ein Filter ist (normalerweise) ein 3x3 Block gefüllt mit weights, wodurch ein bestimmtes Muster repräsentiert wird. Dieser scannt das vorliegende Bild und erkennt anhand der endgültigen Werte die Muster.
</p>
<img src="images/cnn.png"/>
<p>
    Dies passiert natürlich nicht nur einmal hintereinander, sondern so oft, wie es nötig ist, um ein Ergebnis zu erhalten, das die KI erkennen kann. <br>
    Ein positiver Nebeneffekt der CNN ist die Datenminimierung, da für jedes 3x3 Feld, nur ein Wert ausgegeben werden muss.
</p>
<img src="images/cnn.gif"/>
<p>
    Zusammenfassend kann man sagen, dass sich die CNNs mit den rezeptiven Feldern ähneln, da bei beiden Methoden eine Datenminimierung stattfindet, indem man anstatt einzelne Pixel nur noch bestimmte Muster (oder was im Gehirn verwendet wird) weitergeleitet werden und damit, in dem man die einzelnen Muster zusammenführt (in der KI nach bestimmt vielen Schritten, im Gehirn direkt), ein Objekt oder Lebewesen auf dem Bild erkannt werden kann.
</p>
    </div>
</body>

</html>
